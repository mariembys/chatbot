import os
from typing import List, Dict
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
import streamlit as st

# --- Configuration ---
DATA_DIR = "data"                          # Dossier contenant vos documents
VECTORSTORE_DIR = "vectorstore/chroma_db"  # O√π stocker la base vectorielle
CHUNK_SIZE = 500                           # Taille des chunks en tokens (environ)
CHUNK_OVERLAP = 50                         # Chevauchement entre chunks


def charger_documents(data_dir: str = DATA_DIR) -> List:
    """
    Charge tous les documents texte du dossier data/
    
    Returns:
        List: Liste de documents LangChain
    """
    try:
        # Charger tous les fichiers .txt du dossier
        loader = DirectoryLoader(
            data_dir,
            glob="**/*.txt",           # Recherche r√©cursive des .txt
            loader_cls=TextLoader,
            loader_kwargs={'encoding': 'utf-8'}
        )
        documents = loader.load()
        
        st.success(f"‚úÖ {len(documents)} document(s) charg√©(s) depuis '{data_dir}'")
        return documents
    
    except Exception as e:
        st.error(f"‚ùå Erreur lors du chargement des documents : {e}")
        return []


def decouper_documents(documents: List, chunk_size: int = CHUNK_SIZE, 
                       chunk_overlap: int = CHUNK_OVERLAP) -> List:
    """
    D√©coupe les documents en chunks de taille optimale
    
    Args:
        documents: Liste de documents LangChain
        chunk_size: Taille approximative de chaque chunk (en caract√®res)
        chunk_overlap: Nombre de caract√®res de chevauchement entre chunks
    
    Returns:
        List: Liste de chunks (documents plus petits)
    """
    try:
        # Initialiser le text splitter
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            length_function=len,
            separators=["\n\n", "\n", ". ", " ", ""]  # Priorit√© de d√©coupe
        )
        
        # D√©couper tous les documents
        chunks = text_splitter.split_documents(documents)
        
        st.success(f"‚úÖ {len(chunks)} chunks cr√©√©s (taille: {chunk_size} caract√®res, overlap: {chunk_overlap})")
        return chunks
    
    except Exception as e:
        st.error(f"‚ùå Erreur lors du d√©coupage : {e}")
        return []


def creer_embeddings_model():
    """
    Cr√©e le mod√®le d'embeddings multilingue
    
    Utilise le mod√®le LaBSE (Language-agnostic BERT Sentence Embedding)
    qui supporte plus de 100 langues dont le fran√ßais, l'arabe et l'anglais.
    
    Alternative : 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2'
    
    Returns:
        HuggingFaceEmbeddings: Mod√®le d'embeddings
    """
    try:
        # Mod√®le multilingue recommand√© pour votre cas d'usage
        model_name = "sentence-transformers/LaBSE"
        
        embeddings = HuggingFaceEmbeddings(
            model_name=model_name,
            model_kwargs={'device': 'cpu'},  # Utilisez 'cuda' si vous avez un GPU
            encode_kwargs={'normalize_embeddings': True}  # Normalisation pour la similarit√© cosine
        )
        
        st.success(f"‚úÖ Mod√®le d'embeddings '{model_name}' initialis√©")
        return embeddings
    
    except Exception as e:
        st.error(f"‚ùå Erreur lors de l'initialisation du mod√®le d'embeddings : {e}")
        return None


def creer_vectorstore(chunks: List, embeddings, vectorstore_dir: str = VECTORSTORE_DIR):
    """
    Cr√©e ou charge la base de donn√©es vectorielle ChromaDB
    
    Args:
        chunks: Liste de chunks √† vectoriser
        embeddings: Mod√®le d'embeddings
        vectorstore_dir: Chemin o√π sauvegarder la base vectorielle
    
    Returns:
        Chroma: Base de donn√©es vectorielle
    """
    try:
        # Cr√©er le dossier si n√©cessaire
        os.makedirs(vectorstore_dir, exist_ok=True)
        
        # Cr√©er la vectorstore avec ChromaDB
        vectorstore = Chroma.from_documents(
            documents=chunks,
            embedding=embeddings,
            persist_directory=vectorstore_dir
        )
        
        # Sauvegarder sur disque
        vectorstore.persist()
        
        st.success(f"‚úÖ Base vectorielle cr√©√©e avec {len(chunks)} chunks dans '{vectorstore_dir}'")
        return vectorstore
    
    except Exception as e:
        st.error(f"‚ùå Erreur lors de la cr√©ation de la vectorstore : {e}")
        return None


def charger_vectorstore(embeddings, vectorstore_dir: str = VECTORSTORE_DIR):
    """
    Charge une base vectorielle existante
    
    Args:
        embeddings: Mod√®le d'embeddings (doit √™tre le m√™me que celui utilis√© pour cr√©er la base)
        vectorstore_dir: Chemin de la base vectorielle
    
    Returns:
        Chroma: Base de donn√©es vectorielle charg√©e
    """
    try:
        if not os.path.exists(vectorstore_dir):
            st.warning(f"‚ö†Ô∏è La base vectorielle n'existe pas dans '{vectorstore_dir}'")
            return None
        
        vectorstore = Chroma(
            persist_directory=vectorstore_dir,
            embedding_function=embeddings
        )
        
        st.success(f"‚úÖ Base vectorielle charg√©e depuis '{vectorstore_dir}'")
        return vectorstore
    
    except Exception as e:
        st.error(f"‚ùå Erreur lors du chargement de la vectorstore : {e}")
        return None


def pipeline_complet_preparation_dataset():
    """
    Pipeline complet pour l'√©tape 3 : de vos documents √† la base vectorielle
    
    Ce pipeline :
    1. Charge les documents depuis data/
    2. Les d√©coupe en chunks
    3. Cr√©e le mod√®le d'embeddings
    4. Vectorise et stocke dans ChromaDB
    
    Returns:
        Chroma: Base vectorielle pr√™te √† √™tre utilis√©e
    """
    st.header("üìä √âtape 3 : Pr√©paration du Dataset Voyage")
    
    with st.spinner("üìÅ Chargement des documents..."):
        documents = charger_documents()
    
    if not documents:
        st.error("Aucun document trouv√©. Ajoutez des fichiers .txt dans le dossier 'data/'")
        return None
    
    # Afficher un aper√ßu
    with st.expander("üìÑ Aper√ßu des documents charg√©s"):
        for i, doc in enumerate(documents[:3]):  # Afficher les 3 premiers
            st.markdown(f"**Document {i+1}** : `{doc.metadata.get('source', 'N/A')}`")
            st.text(doc.page_content[:200] + "...")
    
    st.divider()
    
    with st.spinner("‚úÇÔ∏è D√©coupage des documents en chunks..."):
        chunks = decouper_documents(documents)
    
    if not chunks:
        return None
    
    # Afficher des statistiques sur les chunks
    with st.expander("üìä Statistiques des chunks"):
        st.write(f"- **Nombre total de chunks** : {len(chunks)}")
        st.write(f"- **Taille moyenne** : {sum(len(c.page_content) for c in chunks) // len(chunks)} caract√®res")
        st.write(f"- **Plus petit chunk** : {min(len(c.page_content) for c in chunks)} caract√®res")
        st.write(f"- **Plus grand chunk** : {max(len(c.page_content) for c in chunks)} caract√®res")
        
        # Afficher 2 exemples de chunks
        st.markdown("**Exemples de chunks :**")
        for i in range(min(2, len(chunks))):
            st.code(chunks[i].page_content, language='text')
    
    st.divider()
    
    with st.spinner("üß† Initialisation du mod√®le d'embeddings multilingue..."):
        embeddings = creer_embeddings_model()
    
    if not embeddings:
        return None
    
    st.divider()
    
    with st.spinner("üî¢ Vectorisation et cr√©ation de la base ChromaDB (peut prendre quelques minutes)..."):
        vectorstore = creer_vectorstore(chunks, embeddings)
    
    if vectorstore:
        st.success("üéâ **√âTAPE 3 TERMIN√âE** : Base vectorielle pr√™te !")
        st.info("üí° Vous pouvez maintenant passer √† l'√©tape 4 : Recherche dans la base vectorielle")
    
    return vectorstore


# --- Fonction utilitaire pour afficher des infos sur la vectorstore ---
def afficher_info_vectorstore(vectorstore):
    """
    Affiche des informations sur la base vectorielle
    """
    if vectorstore:
        st.write("### üìä Informations sur la base vectorielle")
        
        # R√©cup√©rer tous les documents
        collection = vectorstore._collection
        st.write(f"- **Nombre de vecteurs** : {collection.count()}")
        st.write(f"- **Dossier de stockage** : `{vectorstore._persist_directory}`")